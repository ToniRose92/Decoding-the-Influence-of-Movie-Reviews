{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f506f8a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-unnecessary-columns-from-datasets-for-easier-manipulation.\" data-toc-modified-id=\"Remove-unnecessary-columns-from-datasets-for-easier-manipulation.-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Remove unnecessary columns from datasets for easier manipulation.</a></span></li><li><span><a href=\"#Clean-movie-data-using-the-clean_movie_data()-function,-which-includes:\" data-toc-modified-id=\"Clean-movie-data-using-the-clean_movie_data()-function,-which-includes:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Clean movie data using the clean_movie_data() function, which includes:</a></span></li><li><span><a href=\"#Clean-monetary-columns-using-the-clean_money_columns()-function,-which:\" data-toc-modified-id=\"Clean-monetary-columns-using-the-clean_money_columns()-function,-which:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Clean monetary columns using the clean_money_columns() function, which:</a></span></li></ul></li><li><span><a href=\"#Title-Key-Creation-and-Application\" data-toc-modified-id=\"Title-Key-Creation-and-Application-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Title Key Creation and Application</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-title-key-using-the-create_title_key_file()-function,-which:\" data-toc-modified-id=\"Create-a-title-key-using-the-create_title_key_file()-function,-which:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Create a title key using the create_title_key_file() function, which:</a></span></li><li><span><a href=\"#Add-corresponding-title-IDs-to-each-dataset-using-the-add_title_ids()-function,-which:\" data-toc-modified-id=\"Add-corresponding-title-IDs-to-each-dataset-using-the-add_title_ids()-function,-which:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Add corresponding title IDs to each dataset using the add_title_ids() function, which:</a></span></li></ul></li><li><span><a href=\"#Dataset-Compare/Update\" data-toc-modified-id=\"Dataset-Compare/Update-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dataset Compare/Update</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compare-and-update-datasets-with-corresponding-title-IDs-using-the-add_title_id()-function,-which:\" data-toc-modified-id=\"Compare-and-update-datasets-with-corresponding-title-IDs-using-the-add_title_id()-function,-which:-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Compare and update datasets with corresponding title IDs using the add_title_id() function, which:</a></span></li><li><span><a href=\"#Delete-files,-drop-columns,-rename-columns\" data-toc-modified-id=\"Delete-files,-drop-columns,-rename-columns-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Delete files, drop columns, rename columns</a></span></li></ul></li><li><span><a href=\"#Create-reference-files-for-easier-comparison\" data-toc-modified-id=\"Create-reference-files-for-easier-comparison-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create reference files for easier comparison</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-file-for-directors,-actors,-and-genres-will-make-the-analysis-easier\" data-toc-modified-id=\"Creating-a-file-for-directors,-actors,-and-genres-will-make-the-analysis-easier-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Creating a file for directors, actors, and genres will make the analysis easier</a></span></li><li><span><a href=\"#Removing-rows-where-there-is-only-1-title_id\" data-toc-modified-id=\"Removing-rows-where-there-is-only-1-title_id-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Removing rows where there is only 1 title_id</a></span></li></ul></li><li><span><a href=\"#Create-an-updated-title_id_key.csv\" data-toc-modified-id=\"Create-an-updated-title_id_key.csv-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create an updated title_id_key.csv</a></span></li><li><span><a href=\"#Data-File-Split-and-Merge\" data-toc-modified-id=\"Data-File-Split-and-Merge-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Data File Split and Merge</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-each-dataset-split-the-files-to-prepare-for-complete-dataset-build:\" data-toc-modified-id=\"For-each-dataset-split-the-files-to-prepare-for-complete-dataset-build:-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>For each dataset split the files to prepare for complete dataset build:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d09468",
   "metadata": {},
   "source": [
    "The Jupyter notebook is aimed at cleaning and merging movie datasets to create a more cohesive dataset. The cleaning process is done using the 'clean_movie_data()' function that applies several cleaning steps to each file, including converting column names to snake_case, updating columns with spaces, and creating release year/month/day columns.\n",
    "\n",
    "The 'clean_money_columns()' and 'clean_money_string()' functions are helper functions used to clean currency values in the dataset. Once the data is cleaned, the 'add_title_ids()' function is used to merge the datasets using a title ID key to minimize the number of datasets and rows being worked with for better computation.\n",
    "\n",
    "The notebook also includes a section on creating a title key to ensure consistency across multiple datasets. The 'create_title_key_file()' function creates a DataFrame with the title and the number of files it appears in and filters it to keep only titles that appear in at least two files.\n",
    "\n",
    "The 'add_title_id()' function merges two datasets with their respective main datasets by adding a 'title_id' column to the extras datasets. The function is called twice, once for 'movies.csv' and 'movies_extras.csv' and the second time for 'movie_data.csv' and 'movie_data_extras.csv'. The output is saved in the 'cl_extras_reviews' folder.\n",
    "\n",
    "In conclusion, the Jupyter notebook provides an end-to-end solution to cleaning and merging movie datasets to create a cohesive dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163f87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from imports.ipynb\n",
      "importing Jupyter notebook from capstone_functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from common_imports import *\n",
    "from capstone_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62c514",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Remove unnecessary columns from datasets for easier manipulation.\n",
    "\n",
    "### Clean movie data using the clean_movie_data() function, which includes:\n",
    "- Converting column names to snake_case\n",
    "- Cleaning 'title' columns to lowercase with no punctuation or special characters\n",
    "- Creating 'release_year', 'release_month', and 'release_day' columns from 'release_date'\n",
    "- Removing rows with duplicate titles and years, keeping the row with fewest null values\n",
    "- Dropping rows where the release date or year is outside the range of 2002-2022\n",
    "\n",
    "### Clean monetary columns using the clean_money_columns() function, which:\n",
    "- Cleans values in specified columns to remove non-numeric characters and apply multipliers\n",
    "\n",
    "Save cleaned data to new CSV files in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e02a3f",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns for movies_dataset.csv: ['Id', 'title', 'Creative Type', 'Domestic Box Office', 'Franchise', 'Genre', 'International Box Office', 'Keywords', 'Languages', 'MPAA Rating', 'MPAA Rating for', 'Opening Weekend', 'Production Budget', 'Production Companies', 'Production Countries', 'Production Method', 'Running Time Min', 'Source', 'Opening Theater Counts', 'Max Theater Counts', 'Avg Weeks Per Theater', 'Worldwide Box Office', 'release_year', 'release_month', 'release_day', 'release_date']\n",
      "Columns to keep for movies_dataset.csv: ['title', 'Domestic Box Office', 'International Box Office', 'Genre', 'Worldwide Box Office', 'release_year', 'release_month', 'release_day', 'release_date', 'Id', 'Languages']\n",
      "Remaining columns for movies_dataset.csv: ['title', 'Domestic Box Office', 'International Box Office', 'Genre', 'Worldwide Box Office', 'release_year', 'release_month', 'release_day', 'release_date', 'Id', 'Languages']\n",
      "Original columns for metacritic-reviews.csv: ['Title', 'Release Date', 'Rating', 'summary', 'User rating', 'Website rating']\n",
      "Columns to keep for metacritic-reviews.csv: ['Title', 'Rating', 'summary', 'User rating', 'Release Date']\n",
      "Remaining columns for metacritic-reviews.csv: ['Title', 'Rating', 'summary', 'User rating', 'Release Date']\n",
      "Original columns for letterboxd-reviews.csv: ['Title', 'Release Year', 'Reviewer name', 'Review date', 'Review', 'Comment count', 'Like count']\n",
      "Columns to keep for letterboxd-reviews.csv: ['Title', 'Review', 'Review date', 'Comment count', 'Like count', 'Release Year']\n",
      "Remaining columns for letterboxd-reviews.csv: ['Title', 'Review', 'Review date', 'Comment count', 'Like count', 'Release Year']\n",
      "Original columns for rotten_tomatoes_movies.csv: ['id', 'title', 'audience_score', 'tomato_meter', 'rating', 'rating_contents', 'release_date_theaters', 'runtime_minutes', 'genre', 'original_language', 'director', 'writer', 'box_office', 'distributor', 'sound_mix']\n",
      "Columns to keep for rotten_tomatoes_movies.csv: ['title', 'audience_score', 'tomato_meter', 'director', 'id', 'box_office', 'release_date_theaters', 'original_language']\n",
      "Remaining columns for rotten_tomatoes_movies.csv: ['title', 'audience_score', 'tomato_meter', 'director', 'id', 'box_office', 'release_date_theaters', 'original_language']\n",
      "Original columns for movies_extras.csv: ['id', 'tagline', 'credits', 'keywords', 'poster_path', 'backdrop_path']\n",
      "Columns to keep for movies_extras.csv: ['id', 'credits']\n",
      "Remaining columns for movies_extras.csv: ['id', 'credits']\n",
      "Original columns for movie_data.csv: ['Unnamed: 0', 'movie_id', 'original_language', 'overview', 'popularity', 'release_date', 'title', 'vote_average', 'vote_count', 'genres', 'keywords', 'Cast', 'crew']\n",
      "Columns to keep for movie_data.csv: []\n",
      "Remaining columns for movie_data.csv: []\n",
      "Original columns for rotten_tomatoes_movie_reviews.csv: ['id', 'reviewId', 'creationDate', 'criticName', 'isTopCritic', 'originalScore', 'reviewState', 'publicatioName', 'reviewText', 'scoreSentiment', 'reviewUrl']\n",
      "Columns to keep for rotten_tomatoes_movie_reviews.csv: ['reviewText', 'scoreSentiment', 'id', 'isTopCritic', 'originalScore', 'creationDate']\n",
      "Remaining columns for rotten_tomatoes_movie_reviews.csv: ['reviewText', 'scoreSentiment', 'id', 'isTopCritic', 'originalScore', 'creationDate']\n",
      "Original columns for 25k IMDb movie Dataset.csv: ['movie title', 'Rating', 'User Rating', 'Generes', 'Overview', 'Plot Kyeword', 'Director', 'Top 5 Casts', 'Writer', 'year', 'path']\n",
      "Columns to keep for 25k IMDb movie Dataset.csv: ['movie title', 'Rating', 'User Rating', 'Director', 'Top 5 Casts', 'year']\n",
      "Remaining columns for 25k IMDb movie Dataset.csv: ['movie title', 'Rating', 'User Rating', 'Director', 'Top 5 Casts', 'year']\n",
      "Original columns for movies.csv: ['id', 'title', 'genres', 'original_language', 'overview', 'popularity', 'production_companies', 'release_date', 'budget', 'revenue', 'runtime', 'status', 'tagline', 'vote_average', 'vote_count', 'credits', 'keywords', 'poster_path', 'backdrop_path', 'recommendations']\n",
      "Columns to keep for movies.csv: ['title', 'genres', 'popularity', 'budget', 'revenue', 'vote_average', 'vote_count', 'id', 'release_date', 'original_language']\n",
      "Remaining columns for movies.csv: ['title', 'genres', 'popularity', 'budget', 'revenue', 'vote_average', 'vote_count', 'id', 'release_date', 'original_language']\n",
      "Dropping columns completed!\n"
     ]
    }
   ],
   "source": [
    "# Remove unneeded columns to make for easier processing\n",
    "folder_path = '/Users/toniwork/Desktop/AUBEC - 3 Projects/to_clean'\n",
    "output_folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "\n",
    "# Create the output folder if it does not exist\n",
    "create_folder(output_folder_path)\n",
    "\n",
    "# Dictionary to map file names to the columns to keep\n",
    "columns_to_keep = {\n",
    "    'movies_dataset.csv': ['title', 'Domestic Box Office', 'International Box Office', 'Genre', 'Worldwide Box Office', 'release_year', 'release_month', 'release_day', 'release_date', 'Id', 'Languages'],\n",
    "    'metacritic-reviews.csv': ['Title', 'Rating', 'summary', 'User rating', 'Release Date'],\n",
    "    'letterboxd-reviews.csv': ['Title', 'Review', 'Review date', 'Comment count', 'Like count', 'Release Year'],\n",
    "    'rotten_tomatoes_movies.csv': ['title', 'audience_score', 'tomato_meter', 'director', 'id', 'box_office', 'release_date_theaters', 'original_language'],\n",
    "    'rotten_tomatoes_movie_reviews.csv': ['reviewText', 'scoreSentiment', 'id', 'isTopCritic', 'originalScore', 'creationDate'],\n",
    "    '25k IMDb movie Dataset.csv': ['movie title', 'Rating', 'User Rating', 'Director', 'Top 5 Casts', 'year'],\n",
    "    'movies.csv': ['title', 'genres', 'popularity', 'budget', 'revenue', 'vote_average', 'vote_count', 'id', 'release_date', 'original_language'],\n",
    "    'movies_extras.csv': ['id','credits']\n",
    "}\n",
    "\n",
    "# Iterate through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        output_file_path = os.path.join(output_folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Print the original columns\n",
    "        print(f\"Original columns for {filename}: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Get the columns to keep for this file\n",
    "        keep_columns = columns_to_keep.get(filename, [])\n",
    "        \n",
    "        # Print the columns to keep\n",
    "        print(f\"Columns to keep for {filename}: {keep_columns}\")\n",
    "        \n",
    "        # Drop all other columns\n",
    "        df = df[keep_columns]\n",
    "        \n",
    "        # Print the remaining columns\n",
    "        print(f\"Remaining columns for {filename}: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Save the cleaned file to the output folder\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Dropping columns completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5939294",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting movie_data.csv (size: 15872 bytes)\n",
      "Deletion of files under 500KB completed!\n"
     ]
    }
   ],
   "source": [
    "# Delete files with no data \n",
    "\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "\n",
    "# Iterate through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Get the file size in bytes\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    \n",
    "    # Check if the file size is less than 50KB (50KB = 50 * 1024 bytes)\n",
    "    if file_size < 50 * 1024:\n",
    "        print(f\"Deleting {filename} (size: {file_size} bytes)\")\n",
    "        os.remove(file_path)\n",
    "\n",
    "print(\"Deletion of files under 500KB completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956aefcd",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13195 entries, 0 to 13194\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   title                     13195 non-null  object \n",
      " 1   Domestic Box Office       13194 non-null  float64\n",
      " 2   International Box Office  8095 non-null   float64\n",
      " 3   Genre                     12643 non-null  object \n",
      " 4   Worldwide Box Office      8095 non-null   float64\n",
      " 5   release_year              13187 non-null  float64\n",
      " 6   release_month             13185 non-null  float64\n",
      " 7   release_day               13180 non-null  float64\n",
      " 8   release_date              13193 non-null  object \n",
      " 9   Id                        13195 non-null  int64  \n",
      " 10  Languages                 10464 non-null  object \n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 1.1+ MB\n",
      "movies_dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9345 entries, 0 to 9344\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Title         9345 non-null   object \n",
      " 1   Rating        8560 non-null   object \n",
      " 2   summary       9344 non-null   object \n",
      " 3   User rating   7674 non-null   float64\n",
      " 4   Release Date  9345 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 365.2+ KB\n",
      "metacritic-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4596 entries, 0 to 4595\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Title          4596 non-null   object \n",
      " 1   Review         3560 non-null   object \n",
      " 2   Review date    4370 non-null   object \n",
      " 3   Comment count  4273 non-null   object \n",
      " 4   Like count     3318 non-null   float64\n",
      " 5   Release Year   4578 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 215.6+ KB\n",
      "letterboxd-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143258 entries, 0 to 143257\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   title                  142891 non-null  object \n",
      " 1   audience_score         73248 non-null   float64\n",
      " 2   tomato_meter           33877 non-null   float64\n",
      " 3   director               139064 non-null  object \n",
      " 4   id                     143258 non-null  object \n",
      " 5   box_office             14743 non-null   object \n",
      " 6   release_date_theaters  30773 non-null   object \n",
      " 7   original_language      129400 non-null  object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 8.7+ MB\n",
      "rotten_tomatoes_movies.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249325 entries, 0 to 249324\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   id       249325 non-null  int64 \n",
      " 1   credits  151157 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "movies_extras.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1444963 entries, 0 to 1444962\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   reviewText      1375738 non-null  object\n",
      " 1   scoreSentiment  1444963 non-null  object\n",
      " 2   id              1444963 non-null  object\n",
      " 3   isTopCritic     1444963 non-null  bool  \n",
      " 4   originalScore   1009745 non-null  object\n",
      " 5   creationDate    1444963 non-null  object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 56.5+ MB\n",
      "rotten_tomatoes_movie_reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14057 entries, 0 to 14056\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   movie title  14057 non-null  object \n",
      " 1   Rating       12763 non-null  float64\n",
      " 2   User Rating  14057 non-null  object \n",
      " 3   Director     14057 non-null  object \n",
      " 4   Top 5 Casts  14057 non-null  object \n",
      " 5   year         14057 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 659.0+ KB\n",
      "25k IMDb movie Dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 722917 entries, 0 to 722916\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   title              722913 non-null  object \n",
      " 1   genres             511960 non-null  object \n",
      " 2   popularity         722917 non-null  float64\n",
      " 3   budget             722917 non-null  float64\n",
      " 4   revenue            722917 non-null  float64\n",
      " 5   vote_average       722917 non-null  float64\n",
      " 6   vote_count         722917 non-null  float64\n",
      " 7   id                 722917 non-null  int64  \n",
      " 8   release_date       670290 non-null  object \n",
      " 9   original_language  722917 non-null  object \n",
      "dtypes: float64(5), int64(1), object(4)\n",
      "memory usage: 55.2+ MB\n",
      "movies.csv : None\n"
     ]
    }
   ],
   "source": [
    "# Print all file info from step_1 folder, this is to review the column names and data\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823c9380",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Intital clean_movie function to clean up for data consistency\n",
    "def clean_movie_data(folder_path, output_folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: {filename} not found.\")\n",
    "                continue\n",
    "\n",
    "        # Call the cleaning functions\n",
    "        df = convert_column_names(df)\n",
    "        df = clean_title_columns(df)\n",
    "        df = handle_release_dates(df)\n",
    "        df = remove_duplicates(df, columns_to_check=['release_year','title', 'Title', 'movie title'])\n",
    "        df = handle_date_ranges(df,\n",
    "            date_columns=['release_date'],\n",
    "            year_column='year',\n",
    "            start_date='2002-01-01',\n",
    "            end_date='2022-12-31',\n",
    "            start_year=2002,\n",
    "            end_year=2022)\n",
    "        df = convert_string_columns_to_lowercase(df)\n",
    "        df = filter_by_language(df)\n",
    "        \n",
    "        # Save cleaned DataFrame\n",
    "        new_filename = filename\n",
    "        df.to_csv(os.path.join(output_folder_path, new_filename), index=False)\n",
    "        print(f\"{filename} cleaned and saved as {new_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8700f7a6",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 2nd initial clean_movie function to clean up non-numeric to numeric types\n",
    "def clean_movie_data2(folder_path, output_folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: {filename} not found.\")\n",
    "                continue\n",
    "\n",
    "        # Call the cleaning functions\n",
    "        df = clean_money_columns(df, columns=['user_rating', 'box_office', 'comment_count'])       \n",
    "\n",
    "        # Save cleaned DataFrame\n",
    "        new_filename = filename\n",
    "        df.to_csv(os.path.join(output_folder_path, new_filename), index=False)\n",
    "        print(f\"{filename} cleaned and saved as {new_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01ca5ee",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'release_date' column not in 'YYYY-MM-DD' format. Cannot convert non-finite values (NA or inf) to integer\n",
      "movies_dataset.csv cleaned and saved as movies_dataset.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metacritic-reviews.csv cleaned and saved as metacritic-reviews.csv.\n",
      "letterboxd-reviews.csv cleaned and saved as letterboxd-reviews.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten_tomatoes_movies.csv cleaned and saved as rotten_tomatoes_movies.csv.\n",
      "movies_extras.csv cleaned and saved as movies_extras.csv.\n",
      "rotten_tomatoes_movie_reviews.csv cleaned and saved as rotten_tomatoes_movie_reviews.csv.\n",
      "25k IMDb movie Dataset.csv cleaned and saved as 25k IMDb movie Dataset.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "<string>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'release_date' column not in 'YYYY-MM-DD' format. Cannot convert non-finite values (NA or inf) to integer\n",
      "movies.csv cleaned and saved as movies.csv.\n"
     ]
    }
   ],
   "source": [
    "# Run clean_movie_data function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "output_folder_path = '/Users/toniwork/Desktop/Capstone/step_1'  \n",
    "\n",
    "clean_movie_data(folder_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e74873e",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "movies_dataset.csv cleaned and saved as movies_dataset.csv.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "metacritic-reviews.csv cleaned and saved as metacritic-reviews.csv.\n",
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "letterboxd-reviews.csv cleaned and saved as letterboxd-reviews.csv.\n",
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "rotten_tomatoes_movies.csv cleaned and saved as rotten_tomatoes_movies.csv.\n",
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "movies_extras.csv cleaned and saved as movies_extras.csv.\n",
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "rotten_tomatoes_movie_reviews.csv cleaned and saved as rotten_tomatoes_movie_reviews.csv.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "25k IMDb movie Dataset.csv cleaned and saved as 25k IMDb movie Dataset.csv.\n",
      "Column user_rating not found in the DataFrame. Skipping.\n",
      "Column box_office not found in the DataFrame. Skipping.\n",
      "Column comment_count not found in the DataFrame. Skipping.\n",
      "movies.csv cleaned and saved as movies.csv.\n"
     ]
    }
   ],
   "source": [
    "# Run clean_movie_data2 function\n",
    "clean_movie_data2(folder_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94861bd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv :              title  domestic_box_office  international_box_office  \\\n",
      "0   silent trigger              76382.0                       NaN   \n",
      "1         touch me               5000.0                       NaN   \n",
      "2         impostor            6114237.0                 1860370.0   \n",
      "3        spiderman          403706375.0               418000000.0   \n",
      "4  die another day          160942139.0               271000000.0   \n",
      "\n",
      "               genre  worldwide_box_office  release_year  release_month  \\\n",
      "0  thriller/suspense                   NaN           NaN            NaN   \n",
      "1              drama                   NaN           NaN            NaN   \n",
      "2  thriller/suspense             7974607.0        2002.0            1.0   \n",
      "3          adventure           821706375.0        2002.0            5.0   \n",
      "4             action           431942139.0        2002.0           11.0   \n",
      "\n",
      "   release_day release_date    id languages  \n",
      "0          NaN          NaN   577   english  \n",
      "1          NaN          NaN  1014   english  \n",
      "2          4.0   2002-01-04  2789   english  \n",
      "3          3.0   2002-05-03  3280   english  \n",
      "4         22.0   2002-11-22  3281   english  \n",
      "metacritic-reviews.csv :                                                title     rating  \\\n",
      "0  rivers and tides andy goldsworthy working with...       tv-g   \n",
      "1                                           impostor          r   \n",
      "2                         what time is it over there  not rated   \n",
      "3                            brotherhood of the wolf          r   \n",
      "4                                      orange county      pg-13   \n",
      "\n",
      "                                             summary  user_rating  \\\n",
      "0  thomas riedelsheimer's documentary about scott...         76.0   \n",
      "1  a psychological thriller from the future in wh...         76.0   \n",
      "2  a young taipei watch vendor (lee) falls in lov...         67.0   \n",
      "3  inspired by actual events taking place during ...         73.0   \n",
      "4  when his guidance counselor accidentally sends...         71.0   \n",
      "\n",
      "  release_date  release_year  release_month  release_day  \n",
      "0   2002-01-02          2002              1            2  \n",
      "1   2002-01-04          2002              1            4  \n",
      "2   2002-01-11          2002              1           11  \n",
      "3   2002-01-11          2002              1           11  \n",
      "4   2002-01-11          2002              1           11  \n",
      "letterboxd-reviews.csv :                                 title  \\\n",
      "0                           aftersun    \n",
      "1                              joker    \n",
      "2        puss in boots the last wish    \n",
      "3          the banshees of inisherin    \n",
      "4  everything everywhere all at once    \n",
      "\n",
      "                                              review review_date  \\\n",
      "0                  this review may contain spoilers.  2020-01-12   \n",
      "1  if youв??ve never swam in the ocean then of co...  2022-12-20   \n",
      "2                puss in boots: into the pussy-verse  2022-09-15   \n",
      "3  i will not leave my donkey outside when iв??m sad  2022-04-08   \n",
      "4  watch it and have fun before film twitter tell...  2019-08-14   \n",
      "\n",
      "   comment_count  like_count  release_year  \n",
      "0          130.0     22446.0        2022.0  \n",
      "1            NaN     22032.0        2019.0  \n",
      "2           62.0     21666.0        2022.0  \n",
      "3            NaN     21609.0        2022.0  \n",
      "4          355.0     20688.0        2022.0  \n",
      "rotten_tomatoes_movies.csv :                 title  audience_score  tomato_meter               director  \\\n",
      "0  space zombie bingo            50.0           NaN          george ormrod   \n",
      "1     the green grass             NaN           NaN        tiffany edwards   \n",
      "2         sore losers            60.0           NaN  john michael mccarthy   \n",
      "3     dinosaur island            70.0           NaN          will meugniot   \n",
      "4              adrift            65.0          69.0      baltasar kormákur   \n",
      "\n",
      "                     id  box_office release_date_theaters original_language  \n",
      "0    space-zombie-bingo         NaN                   NaN           english  \n",
      "1       the_green_grass         NaN                   NaN           english  \n",
      "2  the_sore_losers_1997         NaN                   NaN           english  \n",
      "3  dinosaur_island_2002         NaN                   NaN           english  \n",
      "4           adrift_2018         NaN            2018-06-01           english  \n",
      "movies_extras.csv :       id                                            credits\n",
      "0  44351  scott coffey-rebekah del rio-laura harring-nao...\n",
      "1  23964  stephen baldwin-callum keith rennie-jessica st...\n",
      "2  36174  martin clunes-victoria hamilton-conleth hill-j...\n",
      "3  31460  sarah jessica parker-harry connick jr.-johnny ...\n",
      "4  26449  jay michael ferguson-allison lange-michael bow...\n",
      "rotten_tomatoes_movie_reviews.csv :                                           reviewtext scoresentiment  \\\n",
      "0  timed to be just long enough for most youngste...       positive   \n",
      "1  it doesn't matter if a movie costs 300 million...       negative   \n",
      "2  the choreography is so precise and lifelike at...       positive   \n",
      "3  the film's out-of-touch attempts at humor may ...       negative   \n",
      "4  its clumsy determination is endearing and some...       positive   \n",
      "\n",
      "                                  id  istopcritic originalscore creationdate  \n",
      "0                            beavers        False         3.5/4   2003-05-23  \n",
      "1                         blood_mask        False           1/5   2007-06-02  \n",
      "2  city_hunter_shinjuku_private_eyes        False           NaN   2019-05-28  \n",
      "3  city_hunter_shinjuku_private_eyes        False         2.5/5   2019-02-14  \n",
      "4                 dangerous_men_2015        False           NaN   2018-08-29  \n",
      "25k IMDb movie Dataset.csv :              movie_title  rating  user_rating           director  \\\n",
      "0  all things fall apart     5.3          NaN  mario van peebles   \n",
      "1                    gun     3.8          NaN      jessy terrero   \n",
      "2       what alice found     6.4          NaN       a. dean bell   \n",
      "3                  happy     7.1          NaN     a. karunakaran   \n",
      "4                   balu     6.0          NaN     a. karunakaran   \n",
      "\n",
      "                                         top_5_casts  year  \n",
      "0  ['brian a. miller', '50 cent', 'ray liotta', '...  2011  \n",
      "1  ['50 cent', 'val kilmer', 'annalynne mccord', ...  2010  \n",
      "2  ['emily grace', 'judith ivey', 'bill raymond',...  2003  \n",
      "3  ['radha mohan', 'darling swamy', 'allu arjun',...  2006  \n",
      "4  ['kona venkat', 'pawan kalyan', 'shriya saran'...  2005  \n",
      "movies.csv :                            title                             genres  \\\n",
      "0        avatar the way of water   science fiction-adventure-action   \n",
      "1  black panther wakanda forever   action-adventure-science fiction   \n",
      "2    puss in boots the last wish  animation-adventure-comedy-family   \n",
      "3            lord of the streets                             action   \n",
      "4              a man called otto                       comedy-drama   \n",
      "\n",
      "   popularity       budget       revenue  vote_average  vote_count      id  \\\n",
      "0    9366.788  350000000.0  2.312336e+09         7.751      6748.0   76600   \n",
      "1    2525.408  250000000.0  8.585356e+08         7.338      3922.0  505642   \n",
      "2    2078.280   90000000.0  4.630876e+08         8.363      4671.0  315162   \n",
      "3    1691.825    1000000.0  0.000000e+00         4.900        29.0  965839   \n",
      "4    1545.382   50000000.0  1.038423e+08         7.811       540.0  937278   \n",
      "\n",
      "  release_date original_language  \n",
      "0   2022-12-14                en  \n",
      "1   2022-11-09                en  \n",
      "2   2022-12-07                en  \n",
      "3   2022-04-22                en  \n",
      "4   2022-12-28                en  \n"
     ]
    }
   ],
   "source": [
    "# Print file header informaition to verify cleaning steps were correctly processed\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56cdb0",
   "metadata": {},
   "source": [
    "## Title Key Creation and Application\n",
    "\n",
    "### Create a title key using the create_title_key_file() function, which:\n",
    "- Loops over all CSV files in a folder and counts the number of times each movie title appears across all files\n",
    "- Creates a DataFrame with the title and the number of files it appears in and filters it to keep only titles that appear in at least two files\n",
    "- Saves the DataFrame to a new CSV file called 'title_key.csv' in the specified output folder path\n",
    "\n",
    "### Add corresponding title IDs to each dataset using the add_title_ids() function, which:\n",
    "- Reads in the 'title_key.csv' file and loops over each file in the specified folder path\n",
    "- Adds a new column called 'title_id' to the DataFrame and loops through each row to add the corresponding title ID from the 'title_key.csv' file\n",
    "- If a title ID is not found, the row is dropped from the DataFrame\n",
    "- Saves the updated CSV file to the specified output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5567d6",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title key file saved as 'title_key.csv'.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258311 entries, 0 to 258310\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   title          258281 non-null  object\n",
      " 1   release_date   258311 non-null  object\n",
      " 2   release_year   258311 non-null  int64 \n",
      " 3   release_month  258311 non-null  int64 \n",
      " 4   release_day    258311 non-null  int64 \n",
      " 5   title_id       258311 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 11.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create title key using create_title_key_file function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "output_folder_path = '/Users/toniwork/Desktop/Capstone'\n",
    "specific_files = ['rotten_tomatoes_movies.csv','letterboxd-reviews.csv','metacritic-reviews.csv',\n",
    "                  '25k IMDb movie Dataset.csv', 'rotten_tomatoes_movie_reviews.csv']\n",
    "columns_to_check = [col for col in df.columns if 'title' in col.lower()]\n",
    "\n",
    "create_title_key_file(folder_path, output_folder_path, specific_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ed0cc7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 215796 entries, 0 to 258310\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   title          215796 non-null  object\n",
      " 1   release_date   215796 non-null  object\n",
      " 2   release_year   215796 non-null  int64 \n",
      " 3   release_month  215796 non-null  int64 \n",
      " 4   release_day    215796 non-null  int64 \n",
      " 5   title_id       215796 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 11.5+ MB\n",
      "Null titles and duplicates dropped, and file saved. None\n"
     ]
    }
   ],
   "source": [
    "# Drop NA and Duplicate rows then print to review \n",
    "file_path = '/Users/toniwork/Desktop/Capstone/title_key.csv'\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows where the 'title' is null or empty\n",
    "df = df[df['title'].notna() & (df['title'] != '')]\n",
    "\n",
    "# Drop duplicate rows based on 'title' and 'release_date'\n",
    "df = df.drop_duplicates(subset=['title', 'release_date'])\n",
    "\n",
    "# Save the DataFrame back to the file or a new file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Null titles and duplicates dropped, and file saved.\",df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c306bfc0",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv and /Users/toniwork/Desktop/Capstone/step_1/movies_dataset.csv\n",
      "metacritic-reviews.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/step_2/metacritic-reviews.csv and /Users/toniwork/Desktop/Capstone/step_1/metacritic-reviews.csv\n",
      "letterboxd-reviews.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/step_2/letterboxd-reviews.csv and /Users/toniwork/Desktop/Capstone/step_1/letterboxd-reviews.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split1.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split1.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split2.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split2.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split3.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split3.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split4.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/rotten_tomatoes_movies_split4.csv\n",
      "4 files concatenated and saved to /Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv\n",
      "25k IMDb movie Dataset.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv and /Users/toniwork/Desktop/Capstone/step_1/25k IMDb movie Dataset.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split1.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split1.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split2.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split2.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split3.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split3.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split4.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split4.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split5.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split5.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split6.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split6.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split7.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split7.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split8.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split8.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split9.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split9.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split10.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split10.csv\n",
      "/Users/toniwork/Desktop/Capstone/split_1/movies_split11.csv cleaned and 'title_id' added. On /Users/toniwork/Desktop/Capstone/split_1/movies_split11.csv\n",
      "11 files concatenated and saved to /Users/toniwork/Desktop/Capstone/step_2/movies.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through file in folder to add the new title_id from the title_key.csv using add_title_ids_main function\n",
    "input_folder = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "title_key_path = '/Users/toniwork/Desktop/Capstone'\n",
    "output_folder = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "split_folder = '/Users/toniwork/Desktop/Capstone/split_1'\n",
    "\n",
    "# Create the output folder if it does not exist\n",
    "create_folder(output_folder)\n",
    "    \n",
    "# Create the split folder if it does not exist\n",
    "create_folder(split_folder)\n",
    "\n",
    "add_title_ids_main(input_folder, title_key_path, split_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f8a9d",
   "metadata": {},
   "source": [
    "## Dataset Compare/Update\n",
    "\n",
    "### Compare and update datasets with corresponding title IDs using the add_title_id() function, which:\n",
    "- Takes in two filenames, the name of the column to match on, the folder path where the files are located, and the output path where the merged files will be saved\n",
    "- Loads the data from the main dataset and the extras dataset, checks if the matching column exists in both datasets, creates a new column for the 'title_id' in the extras dataset, loops through each row in the extras dataset, and checks if the value in the matching column exists in the main dataset\n",
    "- If it does, it adds the corresponding 'title_id' to the new column in the extras dataset\n",
    "- If it doesn't, it drops the row\n",
    "\n",
    "Saves the updated extras dataset to a new CSV file in the specified output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcd6922",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_extras.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/step_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'movies_extras.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through files in folder to add the new title_id from the title_key.csv using add_title_ids_2 function, this compares its counter part file with the title_id to the other\n",
    "\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "compare_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "output_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "movies = 'movies.csv'\n",
    "movies_extras = 'movies_extras.csv'\n",
    "on_col = 'id'\n",
    "\n",
    "# Compare movies.csv and movies_extras.csv, drop rows and add 'title_id' column\n",
    "add_title_ids_2(movies, movies_extras, on_col, folder_path, output_path, compare_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3af9c49",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_chunk.csv split.\n",
      "1_chunk.csv split.\n",
      "2_chunk.csv split.\n",
      "3_chunk.csv split.\n",
      "4_chunk.csv split.\n",
      "5_chunk.csv split.\n",
      "6_chunk.csv split.\n",
      "7_chunk.csv split.\n",
      "8_chunk.csv split.\n",
      "9_chunk.csv split.\n",
      "10_chunk.csv split.\n",
      "11_chunk.csv split.\n",
      "12_chunk.csv split.\n",
      "13_chunk.csv split.\n",
      "14_chunk.csv split.\n",
      "15_chunk.csv split.\n",
      "16_chunk.csv split.\n",
      "17_chunk.csv split.\n",
      "18_chunk.csv split.\n",
      "19_chunk.csv split.\n",
      "20_chunk.csv split.\n",
      "21_chunk.csv split.\n",
      "22_chunk.csv split.\n",
      "23_chunk.csv split.\n",
      "24_chunk.csv split.\n",
      "25_chunk.csv split.\n",
      "26_chunk.csv split.\n",
      "27_chunk.csv split.\n",
      "28_chunk.csv split.\n",
      "29_chunk.csv split.\n",
      "30_chunk.csv split.\n",
      "31_chunk.csv split.\n",
      "32_chunk.csv split.\n",
      "33_chunk.csv split.\n",
      "34_chunk.csv split.\n",
      "35_chunk.csv split.\n",
      "36_chunk.csv split.\n",
      "37_chunk.csv split.\n",
      "38_chunk.csv split.\n",
      "39_chunk.csv split.\n",
      "40_chunk.csv split.\n",
      "41_chunk.csv split.\n",
      "42_chunk.csv split.\n",
      "43_chunk.csv split.\n",
      "44_chunk.csv split.\n",
      "45_chunk.csv split.\n",
      "46_chunk.csv split.\n",
      "47_chunk.csv split.\n",
      "48_chunk.csv split.\n",
      "49_chunk.csv split.\n",
      "50_chunk.csv split.\n",
      "51_chunk.csv split.\n",
      "52_chunk.csv split.\n",
      "53_chunk.csv split.\n",
      "54_chunk.csv split.\n",
      "55_chunk.csv split.\n",
      "56_chunk.csv split.\n",
      "57_chunk.csv split.\n",
      "0_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "1_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "2_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "3_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "4_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "5_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "6_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "7_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "8_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "9_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "10_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "11_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "12_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "13_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "14_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "15_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "16_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "17_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "18_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "19_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "20_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "21_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "22_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "23_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "24_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "25_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "26_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "27_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "28_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "29_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "30_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "31_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "32_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "33_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "34_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "35_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "36_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "37_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "38_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "39_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "40_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "41_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "42_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "43_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "44_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "45_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "46_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "47_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "48_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "49_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "50_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "51_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "52_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "53_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "54_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "55_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "56_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n",
      "57_chunk.csv cleaned and 'title_id' added to /Users/toniwork/Desktop/Capstone/split_1\n"
     ]
    }
   ],
   "source": [
    "# Reads a large CSV file of movie reviews, splits it into smaller chunks, and then processes each chunk using a function add_title_ids_2, applying the transformations and saving the results to the specified paths.\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "compare_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "split_path = '/Users/toniwork/Desktop/Capstone/split_1'\n",
    "\n",
    "rotten_movie_file = 'rotten_tomatoes_movies.csv'\n",
    "rotten_movie_review_file = 'rotten_tomatoes_movie_reviews.csv'\n",
    "on_col = 'id'\n",
    "\n",
    "# Define the chunk size and number of chunks\n",
    "chunk_size = 25000\n",
    "num_chunks = 60\n",
    "\n",
    "# Split the large CSV file into smaller chunks\n",
    "df_reviews = pd.read_csv(os.path.join(folder_path, rotten_movie_review_file), chunksize=chunk_size)\n",
    "for i, chunk in enumerate(df_reviews):\n",
    "    if i >= num_chunks:\n",
    "        break\n",
    "    chunk.to_csv(os.path.join(split_path, f'{i}_chunk.csv'), index=False)\n",
    "    print(f\"{f'{i}_chunk.csv'} split.\")\n",
    "\n",
    "# Loop through the smaller CSV files and apply the add_title_ids_extras() function to each one\n",
    "i = 0\n",
    "while True:\n",
    "    file_path = os.path.join(split_path, f'{i}_chunk.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        break\n",
    "    chunk_df = pd.read_csv(file_path)\n",
    "    add_title_ids_2(rotten_movie_file, f'{i}_chunk.csv', on_col, split_path, split_path, compare_path)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfab84c5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunk files concatenated and saved to /Users/toniwork/Desktop/Capstone/step_2\n"
     ]
    }
   ],
   "source": [
    "# Takes all the \"chunk.csv\" files from the input folder, groups them into three equal parts, and concatenates these parts into three separate CSV files, saving them to the output folder.\n",
    "input_folder = '/Users/toniwork/Desktop/Capstone/split_1'\n",
    "output_folder = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "# Get all files in the input folder that end with \"chunk.csv\"\n",
    "all_files = [f for f in os.listdir(input_folder) if f.endswith(\"chunk.csv\")]\n",
    "\n",
    "# Calculate the number of files per output file\n",
    "num_files_per_output = (len(all_files) + 2) // 3\n",
    "\n",
    "# Initialize output file counter and current output file\n",
    "output_counter = 1\n",
    "current_output_file = os.path.join(output_folder, f\"rotten_tomatoes_movie_reviews_concat{output_counter}.csv\")\n",
    "\n",
    "# Loop through all chunk files\n",
    "for i, file_name in enumerate(all_files):\n",
    "    # Read in chunk file as a DataFrame\n",
    "    chunk_df = pd.read_csv(os.path.join(input_folder, file_name))\n",
    "\n",
    "    # If we have reached the desired number of files per output file, increment output file counter and create new output file\n",
    "    if i > 0 and i % num_files_per_output == 0:\n",
    "        output_counter += 1\n",
    "        current_output_file = os.path.join(output_folder, f\"rotten_tomatoes_movie_reviews_concat{output_counter}.csv\")\n",
    "\n",
    "    # Append chunk DataFrame to current output file\n",
    "    with open(current_output_file, \"a\") as f:\n",
    "        chunk_df.to_csv(f, index=False, header=f.tell()==0)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"All chunk files concatenated and saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aecbbf3f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7256 entries, 0 to 7255\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   title                     7256 non-null   object \n",
      " 1   domestic_box_office       7256 non-null   float64\n",
      " 2   international_box_office  5040 non-null   float64\n",
      " 3   genre                     7220 non-null   object \n",
      " 4   worldwide_box_office      5040 non-null   float64\n",
      " 5   release_year              7255 non-null   float64\n",
      " 6   release_month             7254 non-null   float64\n",
      " 7   release_day               7250 non-null   float64\n",
      " 8   release_date              7255 non-null   object \n",
      " 9   id                        7256 non-null   int64  \n",
      " 10  languages                 7256 non-null   object \n",
      " 11  title_id                  7256 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 680.4+ KB\n",
      "movies_dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9345 entries, 0 to 9344\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          9345 non-null   object \n",
      " 1   rating         8560 non-null   object \n",
      " 2   summary        9344 non-null   object \n",
      " 3   user_rating    7674 non-null   float64\n",
      " 4   release_date   9345 non-null   object \n",
      " 5   release_year   9345 non-null   int64  \n",
      " 6   release_month  9345 non-null   int64  \n",
      " 7   release_day    9345 non-null   int64  \n",
      " 8   title_id       9345 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 657.2+ KB\n",
      "metacritic-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4112 entries, 0 to 4111\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          4112 non-null   object \n",
      " 1   review         3183 non-null   object \n",
      " 2   review_date    3913 non-null   object \n",
      " 3   comment_count  3823 non-null   float64\n",
      " 4   like_count     2978 non-null   float64\n",
      " 5   release_year   4096 non-null   float64\n",
      " 6   title_id       4112 non-null   int64  \n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 225.0+ KB\n",
      "letterboxd-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 389151 entries, 0 to 389150\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   reviewtext      372066 non-null  object\n",
      " 1   scoresentiment  389151 non-null  object\n",
      " 2   id              389151 non-null  object\n",
      " 3   istopcritic     389151 non-null  bool  \n",
      " 4   originalscore   277066 non-null  object\n",
      " 5   creationdate    389151 non-null  object\n",
      " 6   title_id        389151 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 18.2+ MB\n",
      "rotten_tomatoes_movie_reviews_concat2.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 353386 entries, 0 to 353385\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   reviewtext      338466 non-null  object\n",
      " 1   scoresentiment  353386 non-null  object\n",
      " 2   id              353386 non-null  object\n",
      " 3   istopcritic     353386 non-null  bool  \n",
      " 4   originalscore   252212 non-null  object\n",
      " 5   creationdate    353386 non-null  object\n",
      " 6   title_id        353386 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 16.5+ MB\n",
      "rotten_tomatoes_movie_reviews_concat3.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 390377 entries, 0 to 390376\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   reviewtext      373794 non-null  object\n",
      " 1   scoresentiment  390377 non-null  object\n",
      " 2   id              390377 non-null  object\n",
      " 3   istopcritic     390377 non-null  bool  \n",
      " 4   originalscore   279271 non-null  object\n",
      " 5   creationdate    390377 non-null  object\n",
      " 6   title_id        390377 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(5)\n",
      "memory usage: 18.2+ MB\n",
      "rotten_tomatoes_movie_reviews_concat1.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56210 entries, 0 to 56209\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   title                  56210 non-null  object \n",
      " 1   audience_score         36806 non-null  float64\n",
      " 2   tomato_meter           21457 non-null  float64\n",
      " 3   director               55556 non-null  object \n",
      " 4   id                     56210 non-null  object \n",
      " 5   box_office             66 non-null     float64\n",
      " 6   release_date_theaters  24231 non-null  object \n",
      " 7   original_language      56210 non-null  object \n",
      " 8   title_id               56210 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 3.9+ MB\n",
      "rotten_tomatoes_movies.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221684 entries, 0 to 221683\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        221684 non-null  int64 \n",
      " 1   credits   144631 non-null  object\n",
      " 2   title_id  221684 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 5.1+ MB\n",
      "movies_extras.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10291 entries, 0 to 10290\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   movie_title  10291 non-null  object \n",
      " 1   rating       10026 non-null  float64\n",
      " 2   user_rating  2392 non-null   float64\n",
      " 3   director     10291 non-null  object \n",
      " 4   top_5_casts  10291 non-null  object \n",
      " 5   year         10291 non-null  int64  \n",
      " 6   title_id     10291 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 562.9+ KB\n",
      "25k IMDb movie Dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222730 entries, 0 to 222729\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   title              222730 non-null  object \n",
      " 1   genres             152291 non-null  object \n",
      " 2   popularity         222730 non-null  float64\n",
      " 3   budget             222730 non-null  float64\n",
      " 4   revenue            222730 non-null  float64\n",
      " 5   vote_average       222730 non-null  float64\n",
      " 6   vote_count         222730 non-null  float64\n",
      " 7   id                 222730 non-null  int64  \n",
      " 8   release_date       217450 non-null  object \n",
      " 9   original_language  222730 non-null  object \n",
      " 10  title_id           222730 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(4)\n",
      "memory usage: 18.7+ MB\n",
      "movies.csv : None\n"
     ]
    }
   ],
   "source": [
    "# Print file info from folder to verify \n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5e282",
   "metadata": {},
   "source": [
    "### Delete files, drop columns, rename columns\n",
    "- Delete files/folders to clean up space utilization\n",
    "- Drop columns that are no longer needed, such as release date information\n",
    "- Rename columns in order to prepare for merging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a46eb",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Delete folder/files\n",
    "folder_path1 = '/Users/toniwork/Desktop/Capstone/step_1'\n",
    "folder_path2 = '/Users/toniwork/Desktop/Capstone/split_1'\n",
    "\n",
    "# Remove the first folder and its contents\n",
    "shutil.rmtree(folder_path1)\n",
    "\n",
    "# Remove the second folder and its contents\n",
    "shutil.rmtree(folder_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "271fc693",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv updated successfully!\n",
      "metacritic-reviews.csv updated successfully!\n",
      "letterboxd-reviews.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat2.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat3.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat1.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n",
      "movies_extras.csv updated successfully!\n",
      "25k IMDb movie Dataset.csv updated successfully!\n",
      "movies.csv updated successfully!\n",
      "movies_dataset.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat1.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat2.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat3.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n",
      "25k IMDb movie Dataset.csv updated successfully!\n",
      "movies.csv updated successfully!\n",
      "movies_extras.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns using drop_columns_by_keyword_or_name function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "drop_columns_by_keyword_or_name(folder_path, keyword='release')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id', 'languages', 'production_companies'], file_name='movies_dataset.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id'], file_name='rotten_tomatoes_movie_reviews_concat1.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id'], file_name='rotten_tomatoes_movie_reviews_concat2.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id'], file_name='rotten_tomatoes_movie_reviews_concat3.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id', 'original_language'], file_name='rotten_tomatoes_movies.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['year'], file_name='25k IMDb movie Dataset.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id', 'original_language'], file_name='movies.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['id'], file_name='movies_extras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc7eb2b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Rename rating column to mpaa_rating in metacritic-reviews.csv\n",
    "df = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/metacritic-reviews.csv')\n",
    "\n",
    "# Define a dictionary to map old column names to new column names\n",
    "column_mapping = {\n",
    "    'rating': 'mpaa_rating'\n",
    "}\n",
    "\n",
    "# Rename the columns using the dictionary\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "df.to_csv('/Users/toniwork/Desktop/Capstone/step_2/metacritic-reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb21a098",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Rename columns from the rotten_tomatoes_movie_reviews_concat1-3.csv's\n",
    "new_col_names = {\n",
    "    'reviewtext': 'rt_review_text',\n",
    "    'creationdate': 'rt_creation_date',\n",
    "    'istopcritic': 'rt_is_top_critic',\n",
    "    'originalscore': 'rt_original_score',\n",
    "    'scoresentiment' : 'rt_score_sentiment'\n",
    "}\n",
    "\n",
    "# loop through the file paths\n",
    "for file_path in ['/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat1.csv', \n",
    "                  '/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat2.csv', \n",
    "                  '/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat3.csv']:\n",
    "    \n",
    "    # load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # update the column names\n",
    "    df.rename(columns=new_col_names, inplace=True)\n",
    "    \n",
    "    # save the updated DataFrame to the same file path\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8fabe",
   "metadata": {},
   "source": [
    "I am dropping these specific rows from various CSV files to ensure data quality and consistency across my dataset. By removing rows with missing or null values in key columns, I am eliminating potential inaccuracies and focusing on the data that is most relevant to my analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee81d63f",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed movies_dataset.csv\n",
      "Processed metacritic-reviews.csv\n",
      "Processed letterboxd-reviews.csv\n",
      "Processed rotten_tomatoes_movie_reviews_concat2.csv\n",
      "Processed rotten_tomatoes_movie_reviews_concat3.csv\n",
      "Processed rotten_tomatoes_movie_reviews_concat1.csv\n",
      "Processed rotten_tomatoes_movies.csv\n",
      "Processed movies_extras.csv\n",
      "Processed 25k IMDb movie Dataset.csv\n",
      "Processed movies.csv\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows for data consistency\n",
    "\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "file_patterns_to_columns = {\n",
    "    'rotten_tomatoes_movie_reviews_concat': ['rt_review_text'],\n",
    "    'movies_extras.csv': ['credits'],\n",
    "    'metacritic-reviews.csv': ['summary'],\n",
    "    'letterboxd-reviews.csv': ['review'],\n",
    "    'rotten_tomatoes_movies.csv': {'subset': ['audience_score', 'tomato_meter', 'director'], 'how': 'all'}\n",
    "}\n",
    "\n",
    "# Iterate through the files and apply drop_rows function\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        drop_rows(file_path, file_patterns_to_columns)\n",
    "        print(f\"Processed {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5046e36b",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: movies_dataset.csv, Title_id duplicates: 122\n",
      "File: metacritic-reviews.csv, Title_id duplicates: 283\n",
      "File: letterboxd-reviews.csv, Title_id duplicates: 2848\n",
      "File: rotten_tomatoes_movie_reviews_concat2.csv, Title_id duplicates: 369446\n",
      "File: rotten_tomatoes_movie_reviews_concat3.csv, Title_id duplicates: 332261\n",
      "File: rotten_tomatoes_movie_reviews_concat1.csv, Title_id duplicates: 369786\n",
      "File: rotten_tomatoes_movies.csv, Title_id duplicates: 12197\n",
      "File: movies_extras.csv, Title_id duplicates: 19573\n",
      "File: 25k IMDb movie Dataset.csv, Title_id duplicates: 494\n",
      "File: movies.csv, Title_id duplicates: 76225\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates and get count for all updated files in folder\n",
    "folder_path = \"/Users/toniwork/Desktop/Capstone/step_2\"\n",
    "file_pattern = \".csv\" \n",
    "drop_duplicate_rows_and_report(folder_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2d4990e",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6009 entries, 0 to 6008\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   title                     6009 non-null   object \n",
      " 1   domestic_box_office       6009 non-null   float64\n",
      " 2   international_box_office  4029 non-null   float64\n",
      " 3   genre                     5974 non-null   object \n",
      " 4   worldwide_box_office      4029 non-null   float64\n",
      " 5   title_id                  6009 non-null   int64  \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 281.8+ KB\n",
      "movies_dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9344 entries, 0 to 9343\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        9344 non-null   object \n",
      " 1   mpaa_rating  8559 non-null   object \n",
      " 2   summary      9344 non-null   object \n",
      " 3   user_rating  7674 non-null   float64\n",
      " 4   title_id     9344 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 365.1+ KB\n",
      "metacritic-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3183 entries, 0 to 3182\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          3183 non-null   object \n",
      " 1   review         3183 non-null   object \n",
      " 2   review_date    3024 non-null   object \n",
      " 3   comment_count  2957 non-null   float64\n",
      " 4   like_count     2315 non-null   float64\n",
      " 5   title_id       3183 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 149.3+ KB\n",
      "letterboxd-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371565 entries, 0 to 371564\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      371565 non-null  object\n",
      " 1   rt_score_sentiment  371565 non-null  object\n",
      " 2   rt_is_top_critic    371565 non-null  bool  \n",
      " 3   rt_original_score   259712 non-null  object\n",
      " 4   rt_creation_date    371565 non-null  object\n",
      " 5   title_id            371565 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.5+ MB\n",
      "rotten_tomatoes_movie_reviews_concat2.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334216 entries, 0 to 334215\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      334216 non-null  object\n",
      " 1   rt_score_sentiment  334216 non-null  object\n",
      " 2   rt_is_top_critic    334216 non-null  bool  \n",
      " 3   rt_original_score   234345 non-null  object\n",
      " 4   rt_creation_date    334216 non-null  object\n",
      " 5   title_id            334216 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 13.1+ MB\n",
      "rotten_tomatoes_movie_reviews_concat3.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371863 entries, 0 to 371862\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      371863 non-null  object\n",
      " 1   rt_score_sentiment  371863 non-null  object\n",
      " 2   rt_is_top_critic    371863 non-null  bool  \n",
      " 3   rt_original_score   261347 non-null  object\n",
      " 4   rt_creation_date    371863 non-null  object\n",
      " 5   title_id            371863 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.5+ MB\n",
      "rotten_tomatoes_movie_reviews_concat1.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55279 entries, 0 to 55278\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           55279 non-null  object \n",
      " 1   audience_score  36502 non-null  float64\n",
      " 2   tomato_meter    21266 non-null  float64\n",
      " 3   director        55067 non-null  object \n",
      " 4   box_office      66 non-null     float64\n",
      " 5   title_id        55279 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 2.5+ MB\n",
      "rotten_tomatoes_movies.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124128 entries, 0 to 124127\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   credits   124128 non-null  object\n",
      " 1   title_id  124128 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "movies_extras.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10291 entries, 0 to 10290\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   movie_title  10291 non-null  object \n",
      " 1   rating       10026 non-null  float64\n",
      " 2   user_rating  2392 non-null   float64\n",
      " 3   director     10291 non-null  object \n",
      " 4   top_5_casts  10291 non-null  object \n",
      " 5   title_id     10291 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 482.5+ KB\n",
      "25k IMDb movie Dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219375 entries, 0 to 219374\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   title         219375 non-null  object \n",
      " 1   genres        151841 non-null  object \n",
      " 2   popularity    219375 non-null  float64\n",
      " 3   budget        219375 non-null  float64\n",
      " 4   revenue       219375 non-null  float64\n",
      " 5   vote_average  219375 non-null  float64\n",
      " 6   vote_count    219375 non-null  float64\n",
      " 7   title_id      219375 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "movies.csv : None\n"
     ]
    }
   ],
   "source": [
    "# Print file info from folder to verify\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cccf93f",
   "metadata": {},
   "source": [
    "## Create reference files for easier comparison\n",
    "\n",
    "### Creating a file for directors, actors, and genres will make the analysis easier\n",
    "We will create files with a id, the data, and then a comma separated list of the title_ids they appear in\n",
    "- Director\n",
    "    - director_id\n",
    "    - director\n",
    "    - title_ids\n",
    "    - <b>rotten_tomatoes_movies.csv</b> \n",
    "        - director (currently comma separated)\n",
    "    - <b>25k IMDb movie Dataset.csv</b> \n",
    "        - director\n",
    "\n",
    "- Actor\n",
    "    - actor_id\n",
    "    - actor\n",
    "    - title_ids\n",
    "    - <b>movies_extras.csv</b> \n",
    "        - credits (currently separated by -)\n",
    "    - <b>25k IMDb movie Dataset.csv</b> \n",
    "        - top_5_casts (currently in [] and comma separated)\n",
    "\n",
    "- Genre\n",
    "    - genre_id\n",
    "    - genre\n",
    "    - title_ids\n",
    "    - <b>movies_dataset.csv</b> \n",
    "        - genre\n",
    "    - <b>movies.csv</b> \n",
    "        - genres (currently comma separated)\n",
    "        \n",
    "Normalization and Consistency: By separating these entities into individual reference files, we ensure that the information is stored in a normalized and consistent manner. This eliminates redundancy and inconsistencies in the data representation, especially when the information is scattered across different files and formats.\n",
    "\n",
    "Ease of Analysis and Integration: Having dedicated reference files with unique identifiers (director_id, actor_id, genre_id) and associated title_ids allows for more efficient querying, analysis, and integration with other datasets. It simplifies the process of understanding relationships between movies, directors, actors, and genres, and facilitates data-driven insights and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd56e04f",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file /Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv:\n",
      "Processed DataFrame for file /Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv:\n",
      "Read file /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv:\n",
      "directors.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create directors.csv for reference\n",
    "\n",
    "input_files = ['/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv', '/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv']\n",
    "column_names = ['director', 'director']\n",
    "delimiters = [',', None]\n",
    "output_folder = '/Users/toniwork/Desktop/Capstone/merged'\n",
    "output_file = 'directors.csv'\n",
    "merge_columns = 'title_ids'\n",
    "target_column_name = 'directors'\n",
    "\n",
    "create_folder(output_folder)\n",
    "\n",
    "process_data(input_files, column_names, target_column_name, delimiters, output_folder, output_file, merge_columns, num_files=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d225ead",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Make directors title_ids into set, removing duplicates within the set\n",
    "directors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/directors.csv')\n",
    "\n",
    "# Apply the function to the 'title_ids' column\n",
    "directors_df['title_ids'] = directors_df['title_ids'].apply(remove_duplicates_in_set)\n",
    "\n",
    "# Save the updated DataFrame back to CSV \n",
    "directors_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/directors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36cfdabf",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess 25k IMDb movie Dataset.csv to remove [] from one file\n",
    "df = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv')\n",
    "\n",
    "# Strip brackets\n",
    "df['top_5_casts'] = df['top_5_casts'].str.strip('[]')\n",
    "\n",
    "# Save the updated DataFrame back to CSV \n",
    "df.to_csv('/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1408d9b1",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file /Users/toniwork/Desktop/Capstone/step_2/movies_extras.csv:\n",
      "Processed DataFrame for file /Users/toniwork/Desktop/Capstone/step_2/movies_extras.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/movies_extras.csv:\n",
      "Read file /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv:\n",
      "Processed DataFrame for file /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv:\n",
      "actors.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create actors.csv for reference\n",
    "\n",
    "input_files = ['/Users/toniwork/Desktop/Capstone/step_2/movies_extras.csv', '/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv']\n",
    "column_names = ['credits', 'top_5_casts']\n",
    "delimiters = ['-', ',']\n",
    "output_folder = '/Users/toniwork/Desktop/Capstone/merged'\n",
    "output_file = 'actors.csv'\n",
    "merge_columns = 'title_ids'\n",
    "target_column_name = 'actors'\n",
    "\n",
    "create_folder(output_folder)\n",
    "\n",
    "process_data(input_files, column_names, target_column_name, delimiters, output_folder, output_file, merge_columns, remove_quotes=True, num_files=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ce826a9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Make actors title_ids into set, removing duplicates within the set\n",
    "actors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/actors.csv')\n",
    "\n",
    "# Apply the function to the 'title_ids' column\n",
    "actors_df['title_ids'] = actors_df['title_ids'].apply(remove_duplicates_in_set)\n",
    "\n",
    "# Save the updated DataFrame back to CSV \n",
    "actors_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/actors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a8ccc0c",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file /Users/toniwork/Desktop/Capstone/step_2/movies.csv:\n",
      "Processed DataFrame for file /Users/toniwork/Desktop/Capstone/step_2/movies.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/movies.csv:\n",
      "Read file /Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv:\n",
      "Concatenated result DataFrame after file /Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv:\n",
      "genres.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create genres.csv for reference \n",
    "\n",
    "input_files = ['/Users/toniwork/Desktop/Capstone/step_2/movies.csv', '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv']\n",
    "column_names = ['genres','genre']\n",
    "delimiters = ['-',None]\n",
    "output_folder = '/Users/toniwork/Desktop/Capstone/merged'\n",
    "output_file = 'genres.csv'\n",
    "merge_columns = 'title_ids'\n",
    "target_column_name = 'genres'\n",
    "\n",
    "create_folder(output_folder)\n",
    "\n",
    "process_data(input_files, column_names, target_column_name, delimiters, output_folder, output_file, merge_columns, num_files=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0350aa",
   "metadata": {},
   "source": [
    "### Removing rows where there is only 1 title_id\n",
    "\n",
    "In this analysis, we are interested in studying how reviews of one movie impact the next for a given director or actor. To make meaningful comparisons, we need to have at least two movies associated with each director or actor.\n",
    "\n",
    "The 'directors.csv' and 'actors.csv' files contain information about directors and actors, respectively, along with the associated movie title IDs. Some directors and actors may only be associated with a single movie, and in those cases, there would be no \"next\" movie to compare with.\n",
    "\n",
    "To focus our analysis on the entities that have multiple movies, we filter out the rows where there is only one title ID for the director or actor. Specifically, we look for rows where the 'title_ids' column contains at least one comma, indicating that there are multiple title IDs.\n",
    "\n",
    "By doing this, we ensure that our dataset includes only the directors and actors with at least two movies, allowing us to proceed with the comparative analysis between consecutive movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3065701",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Make genre title_ids into set, removing duplicates within the set\n",
    "genres_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/genres.csv')\n",
    "\n",
    "# Apply the function to the 'title_ids' column\n",
    "genres_df['title_ids'] = genres_df['title_ids'].apply(remove_duplicates_in_set)\n",
    "\n",
    "# Save the updated DataFrame back to CSV \n",
    "genres_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "445a1d5d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Turn the title_ids column on directors.csv into a set, this will get rid of any duplicates within the row\n",
    "directors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/directors.csv')\n",
    "\n",
    "# Keep only the rows where there is more than one title ID (i.e., at least one comma in the 'title_ids' column)\n",
    "directors_df = directors_df[directors_df['title_ids'].str.count(',') > 0]\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "directors_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/directors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4c65fd8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Turn the title_ids column on actors.csv into a set, this will get rid of any duplicates within the row\n",
    "actors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/actors.csv')\n",
    "\n",
    "# Keep only the rows where there is more than one title ID\n",
    "actors_df = actors_df[actors_df['title_ids'].str.count(',') > 0]\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "actors_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/actors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "879a41a4",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv updated successfully!\n",
      "metacritic-reviews.csv updated successfully!\n",
      "letterboxd-reviews.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat2.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat3.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat1.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n",
      "movies_extras.csv has only 2 columns. Deleting the entire file.\n",
      "25k IMDb movie Dataset.csv updated successfully!\n",
      "movies.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns used to create the directors, actors, and genres csv\n",
    "path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "columns_to_drop = ['director', 'credits', 'top_5_casts', 'genres', 'genre']\n",
    "\n",
    "# Iterate through all the CSV files in the specified path\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check if the DataFrame has more than 2 columns\n",
    "        if df.shape[1] > 2:\n",
    "            # Drop the specified columns if they exist\n",
    "            df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV file\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"{filename} updated successfully!\")\n",
    "        else:\n",
    "            print(f\"{filename} has only 2 columns. Deleting the entire file.\")\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebbb990a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6009 entries, 0 to 6008\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   title                     6009 non-null   object \n",
      " 1   domestic_box_office       6009 non-null   float64\n",
      " 2   international_box_office  4029 non-null   float64\n",
      " 3   worldwide_box_office      4029 non-null   float64\n",
      " 4   title_id                  6009 non-null   int64  \n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 234.9+ KB\n",
      "movies_dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9344 entries, 0 to 9343\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        9344 non-null   object \n",
      " 1   mpaa_rating  8559 non-null   object \n",
      " 2   summary      9344 non-null   object \n",
      " 3   user_rating  7674 non-null   float64\n",
      " 4   title_id     9344 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 365.1+ KB\n",
      "metacritic-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3183 entries, 0 to 3182\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          3183 non-null   object \n",
      " 1   review         3183 non-null   object \n",
      " 2   review_date    3024 non-null   object \n",
      " 3   comment_count  2957 non-null   float64\n",
      " 4   like_count     2315 non-null   float64\n",
      " 5   title_id       3183 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 149.3+ KB\n",
      "letterboxd-reviews.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371565 entries, 0 to 371564\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      371565 non-null  object\n",
      " 1   rt_score_sentiment  371565 non-null  object\n",
      " 2   rt_is_top_critic    371565 non-null  bool  \n",
      " 3   rt_original_score   259712 non-null  object\n",
      " 4   rt_creation_date    371565 non-null  object\n",
      " 5   title_id            371565 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.5+ MB\n",
      "rotten_tomatoes_movie_reviews_concat2.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334216 entries, 0 to 334215\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      334216 non-null  object\n",
      " 1   rt_score_sentiment  334216 non-null  object\n",
      " 2   rt_is_top_critic    334216 non-null  bool  \n",
      " 3   rt_original_score   234345 non-null  object\n",
      " 4   rt_creation_date    334216 non-null  object\n",
      " 5   title_id            334216 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 13.1+ MB\n",
      "rotten_tomatoes_movie_reviews_concat3.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371863 entries, 0 to 371862\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      371863 non-null  object\n",
      " 1   rt_score_sentiment  371863 non-null  object\n",
      " 2   rt_is_top_critic    371863 non-null  bool  \n",
      " 3   rt_original_score   261347 non-null  object\n",
      " 4   rt_creation_date    371863 non-null  object\n",
      " 5   title_id            371863 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.5+ MB\n",
      "rotten_tomatoes_movie_reviews_concat1.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55279 entries, 0 to 55278\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           55279 non-null  object \n",
      " 1   audience_score  36502 non-null  float64\n",
      " 2   tomato_meter    21266 non-null  float64\n",
      " 3   box_office      66 non-null     float64\n",
      " 4   title_id        55279 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 2.1+ MB\n",
      "rotten_tomatoes_movies.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10291 entries, 0 to 10290\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   movie_title  10291 non-null  object \n",
      " 1   rating       10026 non-null  float64\n",
      " 2   user_rating  2392 non-null   float64\n",
      " 3   title_id     10291 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 321.7+ KB\n",
      "25k IMDb movie Dataset.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219375 entries, 0 to 219374\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   title         219375 non-null  object \n",
      " 1   popularity    219375 non-null  float64\n",
      " 2   budget        219375 non-null  float64\n",
      " 3   revenue       219375 non-null  float64\n",
      " 4   vote_average  219375 non-null  float64\n",
      " 5   vote_count    219375 non-null  float64\n",
      " 6   title_id      219375 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 11.7+ MB\n",
      "movies.csv : None\n"
     ]
    }
   ],
   "source": [
    "# Print file info from folder to verify\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1472b",
   "metadata": {},
   "source": [
    "## Create an updated title_id_key.csv\n",
    "\n",
    "I can then use this title_key_updated DataFrame to merge with other datasets, ensuring that only the rows with matching title_ids are included in the analysis. By doing this, I'll be focusing on the movies that are associated with directors and actors who have at least two movies, aligning with the criteria I've established earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8368f457",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_key_updated.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create an updated title_id (title_key_updated.csv)\n",
    "# Read the directors.csv and actors.csv files\n",
    "directors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/directors.csv')\n",
    "actors_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/actors.csv')\n",
    "\n",
    "# Apply the function to the title_ids column\n",
    "directors_df['title_ids'] = directors_df['title_ids'].apply(convert_to_list)\n",
    "actors_df['title_ids'] = actors_df['title_ids'].apply(convert_to_list)\n",
    "\n",
    "# Explode the title_ids column\n",
    "director_title_ids = directors_df.explode('title_ids')['title_ids'].drop_duplicates()\n",
    "actor_title_ids = actors_df.explode('title_ids')['title_ids'].drop_duplicates()\n",
    "\n",
    "# Combine the title_ids and remove duplicates\n",
    "all_title_ids = pd.concat([director_title_ids, actor_title_ids]).drop_duplicates()\n",
    "\n",
    "# Create a DataFrame for the title_id_key\n",
    "title_id_key_df = pd.DataFrame({'title_id': all_title_ids})\n",
    "\n",
    "# Read the title_key.csv file\n",
    "title_key_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/title_key.csv')\n",
    "\n",
    "# Convert the title_id column to string in both DataFrames\n",
    "title_key_df['title_id'] = title_key_df['title_id'].astype(str)\n",
    "title_id_key_df['title_id'] = title_id_key_df['title_id'].astype(str)\n",
    "\n",
    "# Merge with title_id_key_df using an inner join on the title_id column\n",
    "title_key_updated_df = pd.merge(title_key_df, title_id_key_df, on='title_id', how='inner')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "title_key_updated_df.to_csv('/Users/toniwork/Desktop/Capstone/title_key_updated.csv', index=False)\n",
    "\n",
    "print(\"title_key_updated.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4af9fb8d",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111107 entries, 0 to 111106\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   title          111107 non-null  object\n",
      " 1   release_date   111107 non-null  object\n",
      " 2   release_year   111107 non-null  int64 \n",
      " 3   release_month  111107 non-null  int64 \n",
      " 4   release_day    111107 non-null  int64 \n",
      " 5   title_id       111107 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 5.1+ MB\n",
      "title_key_updated.csv : None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215796 entries, 0 to 215795\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   title          215796 non-null  object\n",
      " 1   release_date   215796 non-null  object\n",
      " 2   release_year   215796 non-null  int64 \n",
      " 3   release_month  215796 non-null  int64 \n",
      " 4   release_day    215796 non-null  int64 \n",
      " 5   title_id       215796 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 9.9+ MB\n",
      "title_key.csv : None\n"
     ]
    }
   ],
   "source": [
    "# Print files info from folder to verify\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read in the CSV file as a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(file_name,':',df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ee2ac2a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: title_key_updated.csv, Title_id duplicates: 0\n",
      "File: title_key.csv, Title_id duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove/check for duplicates in title_key files\n",
    "folder_path = \"/Users/toniwork/Desktop/Capstone\"\n",
    "file_pattern = \".csv\" # Or any specific pattern you want to match\n",
    "drop_duplicate_rows_and_report(folder_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14891dcd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres file updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read the updated key file and update the genre title_ids removing any title_ids in the sets that are not in the title_key_updated.csv\n",
    "title_id_key_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/title_key_updated.csv')\n",
    "\n",
    "# Read the genres file\n",
    "genres_file_path = '/Users/toniwork/Desktop/Capstone/merged/genres.csv'\n",
    "genres_df = pd.read_csv(genres_file_path)\n",
    "\n",
    "# Convert the title_ids in the key file to a set for faster lookup\n",
    "title_id_key_set = set(title_id_key_df['title_id'].astype(str))\n",
    "\n",
    "# Apply the function to the 'title_ids' column\n",
    "genres_df['title_ids'] = genres_df['title_ids'].apply(lambda x: filter_title_ids(x, title_id_key_set))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "genres_df.to_csv(genres_file_path, index=False)\n",
    "print(\"Genres file updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60110a31",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv updated successfully!\n",
      "metacritic-reviews.csv updated successfully!\n",
      "letterboxd-reviews.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat2.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat3.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat1.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n",
      "25k IMDb movie Dataset.csv updated successfully!\n",
      "movies.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Compare title_key_updated to the files in folder step_2 dropping any rows that do not match on title_id \n",
    "title_id_key_df = pd.read_csv('/Users/toniwork/Desktop/Capstone/title_key_updated.csv')\n",
    "path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "# Iterate through all the CSV files in the specified path\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Merge with title_id_key_df using an inner join on the title_id column\n",
    "        # This will keep only the rows with matching title_ids\n",
    "        updated_df = pd.merge(df, title_id_key_df, on='title_id', how='inner')\n",
    "\n",
    "        # Save the updated DataFrame back to the CSV file\n",
    "        updated_df.to_csv(file_path, index=False)\n",
    "        print(f\"{filename} updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c20e7c20",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: movies_dataset.csv, Title_id duplicates: 122\n",
      "File: metacritic-reviews.csv, Title_id duplicates: 283\n",
      "File: letterboxd-reviews.csv, Title_id duplicates: 2745\n",
      "File: rotten_tomatoes_movie_reviews_concat2.csv, Title_id duplicates: 362514\n",
      "File: rotten_tomatoes_movie_reviews_concat3.csv, Title_id duplicates: 326580\n",
      "File: rotten_tomatoes_movie_reviews_concat1.csv, Title_id duplicates: 362742\n",
      "File: rotten_tomatoes_movies.csv, Title_id duplicates: 10649\n",
      "File: 25k IMDb movie Dataset.csv, Title_id duplicates: 485\n",
      "File: movies.csv, Title_id duplicates: 60329\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates and get count for all updated files in step_2 folder\n",
    "folder_path = \"/Users/toniwork/Desktop/Capstone/step_2\"\n",
    "file_pattern = \".csv\" # Or any specific pattern you want to match\n",
    "drop_duplicate_rows_and_report(folder_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1b87a",
   "metadata": {},
   "source": [
    "## Data File Split and Merge\n",
    "\n",
    "### For each dataset split the files to prepare for complete dataset build:\n",
    "Merge files on title_id using the title_key.csv as primary\n",
    "- CSV file 1: Movie Data (create movie_data.csv)\n",
    "    - title_key_id\n",
    "    - title\n",
    "    - release_year\n",
    "    - release_month\n",
    "    - release_day\n",
    "    - release_date\n",
    "    - <b>movies_dataset.csv</b> (merge on/with title_id)\n",
    "        - domestic_box_office\n",
    "        - international_box_office\n",
    "        - worldwide_box_office\n",
    "    - <b>rotten_tomatoes_movies.csv</b> (merge on/with title_id)\n",
    "        - box_office\n",
    "    - <b>movies.csv</b> (merge on/with title_id)\n",
    "        - budget\n",
    "        - revenue\n",
    "        \n",
    "- CSV file 2: Ratings and Reviews (create movie_ratings_reviews.csv)\n",
    "    - title_key_id\n",
    "    - title\n",
    "    - <b>metacritic-reviews.csv</b> (merge on/with title_id)\n",
    "        - mpaa_rating\n",
    "        - summary\n",
    "        - user_rating\n",
    "    - <b>rotten_tomatoes_movies.csv</b> (merge on/with title_id)\n",
    "        - audience_score\n",
    "        - tomato_meter\n",
    "    - <b>letterboxd-reviews.csv</b> (merge on/with title_id)\n",
    "        - review\n",
    "        - review_date\n",
    "        - comment_count\n",
    "        - like_count\n",
    "    - <b>rotten_tomatoes_movie_reviews_concat1-3.csv</b> (merge on/with title_id)\n",
    "        - rt_review_text\n",
    "        - rt_score_sentiment\n",
    "        - rt_is_top_critic\n",
    "        - rt_original_score\n",
    "        - rt_creation_date\n",
    "    - <b>25k IMDb movie Dataset.csv</b> (merge on/with title_id)\n",
    "        - rating\n",
    "        - user_rating\n",
    "    - <b>movies.csv</b> (merge on/with title_id)\n",
    "        - vote_average\n",
    "        - vote_count\n",
    "        - popularity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b713e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Combine and merge box_office and domestic_box_office columns \n",
    "main_file = '/Users/toniwork/Desktop/Capstone/title_key_updated.csv'\n",
    "output_file = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "combine_columns_mapping = {\n",
    "    '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv': ['domestic_box_office'],\n",
    "    '/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv': ['box_office']\n",
    "}\n",
    "rename_combine_column = 'box_office_total'\n",
    "\n",
    "merge_and_combine(main_file, combine_columns_mapping, rename_combine_column, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "daab3d83",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: movie_data.csv, Title_id duplicates: 128\n"
     ]
    }
   ],
   "source": [
    "# Remove/check for duplicates in new movie_data.csv \n",
    "folder_path = \"/Users/toniwork/Desktop/Capstone/merged\"\n",
    "file_pattern = \"movie_data.csv\" \n",
    "drop_duplicate_rows_and_report(folder_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f11f328",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Remove remaining duplicates from movie_data.csv\n",
    "df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/movie_data.csv')\n",
    "\n",
    "df = df.sort_values(by=['title_id', 'box_office_total'], ascending=[True, False])\n",
    "\n",
    "# Drop duplicates based on a specific column, keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='title_id', keep='first')\n",
    "\n",
    "# Write the DataFrame back to a CSV file\n",
    "output_file_path = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6eda1aa2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5633 entries, 0 to 5632\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   international_box_office  3881 non-null   float64\n",
      " 1   worldwide_box_office      3881 non-null   float64\n",
      " 2   title_id                  5633 non-null   int64  \n",
      " 3   release_date              5633 non-null   object \n",
      " 4   release_year              5633 non-null   int64  \n",
      " 5   release_month             5633 non-null   int64  \n",
      " 6   release_day               5633 non-null   int64  \n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 308.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139301 entries, 0 to 139300\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   title_x        139301 non-null  object \n",
      " 1   popularity     139301 non-null  float64\n",
      " 2   budget         139301 non-null  float64\n",
      " 3   revenue        139301 non-null  float64\n",
      " 4   vote_average   139301 non-null  float64\n",
      " 5   vote_count     139301 non-null  float64\n",
      " 6   title_id       139301 non-null  int64  \n",
      " 7   title_y        139301 non-null  object \n",
      " 8   release_date   139301 non-null  object \n",
      " 9   release_year   139301 non-null  int64  \n",
      " 10  release_month  139301 non-null  int64  \n",
      " 11  release_day    139301 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(3)\n",
      "memory usage: 12.8+ MB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "# Print files info from folder to verify\n",
    "movies_dataset = '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv'\n",
    "tomato_movies = '/Users/toniwork/Desktop/Capstone/step_2/movies.csv'\n",
    "\n",
    "df1 = pd.read_csv(movies_dataset)\n",
    "df2 = pd.read_csv(tomato_movies)\n",
    "\n",
    "print(df1.info(), df2.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05fb6b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_dataset.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns using drop_columns_by_keyword_or_name function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_x', 'title_y', 'domestic_box_office'], file_name='movies_dataset.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_x', 'title_y', 'box_office'], file_name='rotten_tomatoes_movies.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_x', 'title_y'], file_name='movies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02590ca0",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def drop_specific_rows(file_path, output_path):\n",
    "    # Read in the CSV file as a DataFrame\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Define a condition to filter rows where both specified columns are NA or zero\n",
    "    condition = ((df['international_box_office'].isna() | (df['international_box_office'] == 0)) &\n",
    "                 (df['worldwide_box_office'].isna() | (df['worldwide_box_office'] == 0)))\n",
    "\n",
    "    # Drop rows that meet the condition\n",
    "    df.drop(df[condition].index, inplace=True)\n",
    "\n",
    "    # Save the DataFrame back to the file\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# File path to process\n",
    "file_path = '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset.csv'\n",
    "output_path = '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset_revenue.csv'\n",
    "drop_specific_rows(file_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e94d5c84",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def drop_specific_rows(file_path, output_path):\n",
    "    # Read in the CSV file as a DataFrame\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Define a condition to filter rows where both specified columns are NA or zero\n",
    "    condition = ((df['budget'].isna() | (df['budget'] == 0)) &\n",
    "                 (df['revenue'].isna() | (df['revenue'] == 0)))\n",
    "\n",
    "    # Drop rows that meet the condition\n",
    "    df.drop(df[condition].index, inplace=True)\n",
    "\n",
    "    # Save the DataFrame back to the file\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# File path to process\n",
    "file_path = '/Users/toniwork/Desktop/Capstone/step_2/movies.csv'\n",
    "output_path = '/Users/toniwork/Desktop/Capstone/step_2/movies_revenue.csv'\n",
    "drop_specific_rows(file_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "911f5e54",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def add_columns(target_file, columns_to_add):\n",
    "    target_df = pd.read_csv(target_file)\n",
    "\n",
    "    for file_path, columns in columns_to_add.items():\n",
    "        input_df = pd.read_csv(file_path, usecols=['title_id'] + columns)\n",
    "        \n",
    "        # Merge the data\n",
    "        target_df = pd.merge(target_df, input_df, on='title_id', how='left')\n",
    "\n",
    "    target_df.to_csv(target_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7431bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = {\n",
    "    '/Users/toniwork/Desktop/Capstone/title_key_updated.csv': ['title', 'release_date', 'release_year', 'release_month', 'release_day'],\n",
    "    '/Users/toniwork/Desktop/Capstone/step_2/movies_dataset_revenue.csv': ['international_box_office', 'worldwide_box_office'],\n",
    "    '/Users/toniwork/Desktop/Capstone/step_2/movies_revenue.csv': ['budget', 'revenue']\n",
    "}\n",
    "\n",
    "target_file = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "add_columns(target_file, columns_to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4befca4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: movie_data.csv, Title_id duplicates: 638\n"
     ]
    }
   ],
   "source": [
    "# Remove/check for duplicates in new movie_data.csv \n",
    "folder_path = \"/Users/toniwork/Desktop/Capstone/merged\"\n",
    "file_pattern = \"movie_data.csv\" \n",
    "drop_duplicate_rows_and_report(folder_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd8ad730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove remaining duplicates from movie_data.csv\n",
    "df = pd.read_csv('/Users/toniwork/Desktop/Capstone/merged/movie_data.csv')\n",
    "\n",
    "df = df.sort_values(by=['title_id', 'budget', 'revenue', 'box_office_total'], ascending=[True, False, False, False])\n",
    "\n",
    "# Drop duplicates based on a specific column, keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='title_id', keep='first')\n",
    "\n",
    "# Write the DataFrame back to a CSV file\n",
    "output_file_path = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f27b3fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5675 entries, 0 to 5674\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   title_id                    5675 non-null   int64  \n",
      " 1   box_office_total            5675 non-null   object \n",
      " 2   title_x                     5675 non-null   object \n",
      " 3   international_box_office_x  3993 non-null   float64\n",
      " 4   worldwide_box_office_x      3993 non-null   float64\n",
      " 5   budget_x                    4032 non-null   float64\n",
      " 6   revenue_x                   4032 non-null   float64\n",
      " 7   release_date_y              5675 non-null   object \n",
      " 8   release_year_y              5675 non-null   int64  \n",
      " 9   release_month_y             5675 non-null   int64  \n",
      " 10  release_day_y               5675 non-null   int64  \n",
      "dtypes: float64(4), int64(4), object(3)\n",
      "memory usage: 487.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print files info from folder to verify\n",
    "movie_data = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "\n",
    "df1 = pd.read_csv(movie_data)\n",
    "\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5591d5a3",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_data.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns using drop_columns_by_keyword_or_name function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/merged'\n",
    "\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_y', 'domestic_box_office', 'release_date_x', 'release_year_x', 'release_month_x', 'release_day_x', 'international_box_office_y', 'worldwide_box_office_y', 'budget_y', 'revenue_y'], file_name='movie_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4ae5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_duplicates_and_nulls(df, duplicate_column):\n",
    "    # Identify duplicates in the specified column\n",
    "    duplicates = df.duplicated(subset=duplicate_column, keep=False)\n",
    "    duplicate_df = df[duplicates]\n",
    "\n",
    "    # Print the number of duplicates\n",
    "    print(f\"Number of duplicates in {duplicate_column}: {len(duplicate_df)}\")\n",
    "\n",
    "    # Check for null or zero values in all columns\n",
    "    for column in duplicate_df.columns:\n",
    "        null_count = duplicate_df[column].isnull().sum()\n",
    "        zero_count = (duplicate_df[column] == 0).sum()\n",
    "        print(f\"Number of null values in {column} among duplicates: {null_count}\")\n",
    "        print(f\"Number of zero values in {column} among duplicates: {zero_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfe27e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in title_id: 0\n",
      "Number of null values in title_id among duplicates: 0\n",
      "Number of zero values in title_id among duplicates: 0\n",
      "Number of null values in box_office_total among duplicates: 0\n",
      "Number of zero values in box_office_total among duplicates: 0\n",
      "Number of null values in title among duplicates: 0\n",
      "Number of zero values in title among duplicates: 0\n",
      "Number of null values in release_date among duplicates: 0\n",
      "Number of zero values in release_date among duplicates: 0\n",
      "Number of null values in release_year among duplicates: 0\n",
      "Number of zero values in release_year among duplicates: 0\n",
      "Number of null values in release_month among duplicates: 0\n",
      "Number of zero values in release_month among duplicates: 0\n",
      "Number of null values in release_day among duplicates: 0\n",
      "Number of zero values in release_day among duplicates: 0\n",
      "Number of null values in international_box_office among duplicates: 0\n",
      "Number of zero values in international_box_office among duplicates: 0\n",
      "Number of null values in worldwide_box_office among duplicates: 0\n",
      "Number of zero values in worldwide_box_office among duplicates: 0\n",
      "Number of null values in budget among duplicates: 0\n",
      "Number of zero values in budget among duplicates: 0\n",
      "Number of null values in revenue among duplicates: 0\n",
      "Number of zero values in revenue among duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file as a DataFrame\n",
    "file_path = '/Users/toniwork/Desktop/Capstone/merged/movie_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Call the function with the DataFrame and the column to check for duplicates\n",
    "print_duplicates_and_nulls(df, duplicate_column='title_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e7a1d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7648 entries, 0 to 7647\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   mpaa_rating  7190 non-null   object \n",
      " 1   summary      7648 non-null   object \n",
      " 2   user_rating  6519 non-null   float64\n",
      " 3   title_id     7648 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 239.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3068 entries, 0 to 3067\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   review         3068 non-null   object \n",
      " 1   review_date    2915 non-null   object \n",
      " 2   comment_count  2851 non-null   float64\n",
      " 3   like_count     2231 non-null   float64\n",
      " 4   title_id       3068 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 120.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139301 entries, 0 to 139300\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   popularity    139301 non-null  float64\n",
      " 1   vote_average  139301 non-null  float64\n",
      " 2   vote_count    139301 non-null  float64\n",
      " 3   title_id      139301 non-null  int64  \n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 4.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10216 entries, 0 to 10215\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   rating       9955 non-null   float64\n",
      " 1   user_rating  2354 non-null   float64\n",
      " 2   title_id     10216 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 239.6 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49491 entries, 0 to 49490\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   audience_score  34650 non-null  float64\n",
      " 1   tomato_meter    20189 non-null  float64\n",
      " 2   title_id        49491 non-null  int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 1.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 364593 entries, 0 to 364592\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      364593 non-null  object\n",
      " 1   rt_score_sentiment  364593 non-null  object\n",
      " 2   rt_is_top_critic    364593 non-null  bool  \n",
      " 3   rt_original_score   256856 non-null  object\n",
      " 4   rt_creation_date    364593 non-null  object\n",
      " 5   title_id            364593 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 364398 entries, 0 to 364397\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      364398 non-null  object\n",
      " 1   rt_score_sentiment  364398 non-null  object\n",
      " 2   rt_is_top_critic    364398 non-null  bool  \n",
      " 3   rt_original_score   255321 non-null  object\n",
      " 4   rt_creation_date    364398 non-null  object\n",
      " 5   title_id            364398 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 14.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 328348 entries, 0 to 328347\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   rt_review_text      328348 non-null  object\n",
      " 1   rt_score_sentiment  328348 non-null  object\n",
      " 2   rt_is_top_critic    328348 non-null  bool  \n",
      " 3   rt_original_score   230766 non-null  object\n",
      " 4   rt_creation_date    328348 non-null  object\n",
      " 5   title_id            328348 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 12.8+ MB\n",
      "None None None None None None None None\n"
     ]
    }
   ],
   "source": [
    "# Print files info from folder to verify\n",
    "df1 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/metacritic-reviews.csv')\n",
    "df2 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/letterboxd-reviews.csv')\n",
    "df3 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/movies.csv')\n",
    "df4 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv')\n",
    "df5 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv')\n",
    "df6 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat1.csv')\n",
    "df7 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat2.csv')\n",
    "df8 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movie_reviews_concat3.csv')\n",
    "\n",
    "print(df1.info(), df2.info(), df3.info(), df4.info(), df5.info(), df6.info(), df7.info(), df8.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f41b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metacritic-reviews.csv updated successfully!\n",
      "letterboxd-reviews.csv updated successfully!\n",
      "movies.csv updated successfully!\n",
      "25k IMDb movie Dataset.csv updated successfully!\n",
      "rotten_tomatoes_movies.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat1.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat2.csv updated successfully!\n",
      "rotten_tomatoes_movie_reviews_concat3.csv updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns using drop_columns_by_keyword_or_name function\n",
    "folder_path = '/Users/toniwork/Desktop/Capstone/step_2'\n",
    "\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_y', 'title_x', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='metacritic-reviews.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_y', 'title_x', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='letterboxd-reviews.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title_y', 'title_x', 'release_date', 'release_year', 'release_month', 'release_day', 'budget', 'revenue'], file_name='movies.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title', 'movie_title', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='25k IMDb movie Dataset.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['release_date', 'release_year', 'release_month', 'release_day'], file_name='rotten_tomatoes_movies.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='rotten_tomatoes_movie_reviews_concat1.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='rotten_tomatoes_movie_reviews_concat2.csv')\n",
    "drop_columns_by_keyword_or_name(folder_path, column_names=['title', 'release_date', 'release_year', 'release_month', 'release_day'], file_name='rotten_tomatoes_movie_reviews_concat3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd8e9efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "df1 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/metacritic-reviews.csv')\n",
    "df2 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/letterboxd-reviews.csv')\n",
    "df3 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/movies.csv')\n",
    "df4 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/25k IMDb movie Dataset.csv')\n",
    "df5 = pd.read_csv('/Users/toniwork/Desktop/Capstone/step_2/rotten_tomatoes_movies.csv')\n",
    "\n",
    "# Merge the DataFrames on the common title_id\n",
    "merged_df = df1.merge(df2, on='title_id', how='inner')\n",
    "merged_df = merged_df.merge(df3, on='title_id', how='inner')\n",
    "merged_df = merged_df.merge(df4, on='title_id', how='inner')\n",
    "merged_df = merged_df.merge(df5, on='title_id', how='inner')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('/Users/toniwork/Desktop/Capstone/merged/reviews_ratings.csv', index=False)\n",
    "\n",
    "print(\"Files merged successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c6079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f0cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950fd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "196px",
    "width": "161px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "371.906px",
    "left": "10px",
    "top": "150px",
    "width": "521px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
